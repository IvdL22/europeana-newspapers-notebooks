{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18de12fd-6d7c-40ec-b853-bcfbd1abe2e5",
   "metadata": {},
   "source": [
    "# Counting all the words in one newspaper set\n",
    "\n",
    "In this example, we count all the words in a single newspaper set. \n",
    "\n",
    "**Note that this example only works if the data directory is populated with (at least) the set that we configure in the beginning of the example. If the data has not yet been retrieved and stored in this environment, please run the data retrieval script first!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b2564-b8d7-4980-9003-bbcbc30f416c",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Configure the dataset to process. To see which data sets are actually available in this environment, see the contents of the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cee204d-79c6-431c-a5c6-093352fedc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To count words in a set, remove the '#' from the corresponding line and make sure that all the other lines do start with a '#' (commenting/uncommenting)\n",
    "\n",
    "# dataset = '9200300' # Austria\n",
    "# dataset = '9200301' # Finland\n",
    "# dataset = '9200303' # Latvia\n",
    "# dataset = '9200338' # Hamburg\n",
    "# dataset = '9200339' # Serbia\n",
    "# dataset = '9200355' # Berlin\n",
    "# dataset = '9200356' # Estonia\n",
    "# dataset = '9200357' # Poland\n",
    "# dataset = '9200359' # Netherlands\n",
    "dataset = '9200396' # Luxembourg\n",
    "\n",
    "from os.path import expanduser\n",
    "datadir = expanduser(\"~\") + '/work/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db0e25-505d-4711-8a26-9bd4e2c30a09",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Load the JSON object from the dataset directory that provides a mapping from object identifier to the text file with full text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bca765f6-4062-4611-992b-e1f079d806fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loaded map for data set 9200396: 1,317 items'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "set_dir = f'{datadir}/{dataset}'\n",
    "with open(f'{set_dir}/id_file_map.json','r') as f:\n",
    "    map = json.load(f)\n",
    "\n",
    "f'Loaded map for data set {dataset}: {len(map):,} items'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad81f162-d453-4be1-9178-4e8142090228",
   "metadata": {},
   "source": [
    "## Processing\n",
    "\n",
    "Count the total number of words (whitespace separated substrings) in the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c618bf27-000a-48c7-b1cb-7658d86e24cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total word count: 29,266,765 words'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = 0\n",
    "for id in map:\n",
    "    filename = map[id]\n",
    "    with open(f'{set_dir}/{filename}', 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            word_count += len(str.split(line))\n",
    "\n",
    "f'Total word count: {word_count:,} words'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
