{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d95b42d-f8ed-41af-a21b-53fd5aa96256",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise 3: data filtering and running NLP tasks\n",
    "\n",
    "In this exercise you will first learn how to use metadata properties for filtering data. We will then apply this to an example NLP pipeline.\n",
    "\n",
    "----\n",
    "Like in the previous exercise, we first need to install and 'import' some packages. Run the following cell to get everything in place. Notice that this is a cell that might take a bit more time to run. While `[*]` is shown next to a cell, this means that it is being processed or waiting to be processed and has not yet completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5c51ea62-15a0-4df9-b095-029742393adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.9/site-packages (4.9.0)\n",
      "Looking in indexes: https://pypi.clarin-pl.eu\n",
      "Requirement already satisfied: lpmn_client in /opt/conda/lib/python3.9/site-packages (1.4.6)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from lpmn_client) (6.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from lpmn_client) (4.62.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from lpmn_client) (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->lpmn_client) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->lpmn_client) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->lpmn_client) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->lpmn_client) (2.0.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml\n",
    "!pip install -i https://pypi.clarin-pl.eu lpmn_client\n",
    "\n",
    "from lxml import etree\n",
    "import requests\n",
    "from lpmn_client import download_file, upload_file\n",
    "from lpmn_client import Task\n",
    "\n",
    "%run ../common.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04a9151-6d39-42cf-95b7-aa02a680d1a9",
   "metadata": {},
   "source": [
    "## Exercise 3.1\n",
    "\n",
    "For many research questions, we want to analyse one or more specific data segments based on some criteria. For this exercise we assume that we are interested to find names of persons, organisations, places etcetera found in texts mentioning the city of Kraków published in the first week of World War I.\n",
    "\n",
    "In the next cells, create the list of file paths of resources that meet these criteria:\n",
    "- publication date between 28 July 1914 and 4 August 1914\n",
    "- the resource file contains the text 'Kraków'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5c3b33e8-c868-416f-84a1-e4011ddbe6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving https://europeana-oai.clarin.eu/metadata/fulltext-aggregation/9200357.zip\n",
      "Extracting content in /home/jovyan/temp/metadata/9200357\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/temp/metadata/9200357'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the metadata. We put this in its own cell so that we can run the filtering process separately\n",
    "set_metadata_dir = unpack_metadata(set_id, metadata_dir)\n",
    "\n",
    "set_metadata_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5902b50-27c6-4472-9145-c7ce8d789a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We provide two helper functions that gets all issue identifiers and the associated dates out of\n",
    "# a metadata record. You can use this as is.\n",
    "\n",
    "def get_issues_id_and_date(metadata_tree):\n",
    "    \"\"\"\n",
    "        Returns a list of tuples (id, date) for all issues in the metadata tree.\n",
    "        The 'date' part is a date object that supports retrieval of the date parts, i.e.\n",
    "        `date.year`, `date.month`, `date.day`\n",
    "    \"\"\"\n",
    "    issue_descriptions = metadata_tree.xpath('//cmdp_text:SubresourceDescription', namespaces=nsmap)\n",
    "    issues = [get_id_and_date_from_description(description) for description in issue_descriptions  if description is not None]\n",
    "    return [issue for issue in issues if issue is not None]\n",
    "\n",
    "def get_id_and_date_from_description(description_element):\n",
    "    \"\"\"\n",
    "        Helper that gets the identifier and date for a single issue. Returns None\n",
    "        if there is identifier and date information are not both present.\n",
    "    \"\"\"\n",
    "    issue_ids = description_element.findall('./cmdp_text:IdentificationInfo/cmdp_text:identifier', namespaces=nsmap)\n",
    "    issue_dates_start = description_element.find('./cmdp_text:TemporalCoverage/cmdp_text:Start/cmdp_text:date', namespaces=nsmap)\n",
    "    if len(issue_ids) > 0 and issue_dates_start is not None:\n",
    "        for issue_id in issue_ids:\n",
    "            if issue_id.text.isnumeric():\n",
    "                return (issue_id.text, datetime.date.fromisoformat(issue_dates_start.text))\n",
    "\n",
    "\n",
    "files = []\n",
    "for metadata_file in os.listdir(set_metadata_dir):\n",
    "    full_path = f'{set_metadata_dir}/{metadata_file}'\n",
    "    tree = etree.parse(full_path)\n",
    "    for info in get_issues_id_and_date(tree):\n",
    "        (issue_id, issue_date) = info\n",
    "        # We now have a numer identifier `issue_id` and a date `issue_date`\n",
    "        # from which we can get the year, month, day through `issue_date.year`,\n",
    "        # `issue_date.month`, `issue_date.day`. Use this to decide whether to include \n",
    "        # this issue.\n",
    "        \n",
    "        # If the date matches the desired range, we need to look at the resource itself\n",
    "        # to see if the target text appears.\n",
    "        # If you want, you can make use of the provided function get_resource_file(issue_id)\n",
    "        # to determine the path to the file.\n",
    "        #\n",
    "        # In Exercises set 2 we explored how to open a file and look for text inside\n",
    "        \n",
    "        # If both criteria match, we only need to add the file path to the array, which is\n",
    "        # done with `files.append(issue_id)`\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3cefa6-f387-4f77-b3de-c5625141fc8f",
   "metadata": {},
   "source": [
    "In the next cell we compore the result to a predefined solution. In the following cells we will use the outcome of the predefined solution, so don't worry about moving on even if the outcomes do not fully match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2ce3560b-c5aa-478d-9d1f-35af18925b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in our own result: 0\n",
      "Number of files in result from predefined solution: 7\n",
      "The counts do not match :(\n"
     ]
    }
   ],
   "source": [
    "my_result = files\n",
    "print(f'Number of files in our own result: {len(my_result)}')\n",
    "\n",
    "# now we run the predefined solution\n",
    "predefined_result = ex3_filter_by_date_and_content(set_metadata_dir,\n",
    "                                       date.fromisoformat('1914-07-28'), \n",
    "                                       date.fromisoformat('1914-08-11'), 'w Polsce')\n",
    "print(f'Number of files in result from predefined solution: {len(predefined_result)}')\n",
    "\n",
    "if len(my_result) == len(predefined_result):\n",
    "    print('The counts match!')\n",
    "else:\n",
    "    print('The counts do not match :(')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc6fa08-48bf-4ac7-a7f7-6b887aaf16e0",
   "metadata": {},
   "source": [
    "## Exercise 3.2\n",
    "In this exercise we will submit our selection of files to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f32b123a-a3c4-4fd4-aeda-ef9332e295d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100.0/100 [00:02<00:00, 40.44it/s]\n",
      "100%|██████████| 100.0/100 [00:07<00:00, 12.52it/s]\n",
      "100%|██████████| 100.0/100 [00:04<00:00, 24.85it/s]\n",
      "100%|██████████| 100.0/100 [00:03<00:00, 25.07it/s]\n",
      "100%|██████████| 100.0/100 [00:04<00:00, 20.85it/s]\n",
      "100%|██████████| 100.0/100 [00:02<00:00, 41.48it/s]\n",
      "100%|██████████| 100.0/100 [00:04<00:00, 24.55it/s]\n"
     ]
    }
   ],
   "source": [
    "resource_files = predefined_result\n",
    "\n",
    "# Here we define a function for tasking lpmn client with Liner2 NER pipeline with task size control \n",
    "\n",
    "def liner2_NER(resources, names=[]):\n",
    "    \"\"\"\n",
    "        Wrap over CLARIN-PL lpmn client with control of the task size in order to avoid jamming the task queue on the server side\n",
    "        \n",
    "        :param list resources: list of paths to the resources to be processed\n",
    "        :returns list: list of paths to the output zip files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Size check\n",
    "    _check_task_size(resources)\n",
    "    # Upload reasources to task queue\n",
    "    job_ids = [upload_file(resource_file) for resource_file in resources]\n",
    "    # Specify pipeline \n",
    "    t = Task(\"any2txt|wcrft2|liner2\")\n",
    "    # Run uploaded tasks with pipeline\n",
    "    output_file_ids = [t.run(job_id, verbose=True) for job_id in job_ids]\n",
    "    if names:\n",
    "        liner2_output = [download_file(output_file_id, output_file, filename) for output_file_id, filename in zip(output_file_ids, names)]\n",
    "    else:\n",
    "        liner2_output = [download_file(output_file_id, output_file) for output_file_id in output_file_ids]\n",
    "    return liner2_output\n",
    "\n",
    "output = liner2_NER(resource_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7692ef11-0e3d-4e15-bd30-b84dfbfe271b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/output/6be59c9d-6615-4cb4-8dc3-5bd251a7f456.zip',\n",
       " '/home/jovyan/output/ccf2c814-824d-43ef-9da8-ba788b4135c5.zip',\n",
       " '/home/jovyan/output/c707f80c-db37-4c6d-9859-e20bf3459401.zip',\n",
       " '/home/jovyan/output/3979126f-f03a-4669-96a9-3d5a95d86ebc.zip',\n",
       " '/home/jovyan/output/13b31721-6040-4754-8dc9-6d4e2073834d.zip',\n",
       " '/home/jovyan/output/4940cf2e-7a0f-4ef7-b7f1-eb7510f9468b.zip',\n",
       " '/home/jovyan/output/db34271d-cb3c-4d03-ba80-55506d1a0544.zip']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c985b5-6126-4df9-b3a6-e5066a2938c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
